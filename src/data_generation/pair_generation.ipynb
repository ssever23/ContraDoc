{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting sentences\n",
    "import fitz  # PyMuPDF\n",
    "import nltk\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# pair generation\n",
    "import openai\n",
    "import json\n",
    "from category_types import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extract sentences from documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/user123/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download punkt tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break content of pdf files into individual sentences\n",
    "\"\"\"\n",
    "folder_path = \"/home/ssever/contradictory-information/data/sentence_data\"\n",
    "\n",
    "pdf_files = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    full_text = \"\"\n",
    "    doc = fitz.open(pdf_file)\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    \n",
    "    doc.close()\n",
    "\n",
    "    sentences = nltk.tokenize.sent_tokenize(full_text)\n",
    "\n",
    "    all_sentences.append(sentences)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 21431\n"
     ]
    }
   ],
   "source": [
    "# remove all newline characters\n",
    "\"\"\"\n",
    "flattened_and_cleaned_list = [item.replace(\"\\n\", \"\") for sublist in all_sentences for item in sublist]\n",
    "print(f\"Number of sentences:\", len(flattened_and_cleaned_list))\n",
    "#flattened_and_cleaned_list.index('Fitch Ratings continued to award the Group a long-term issuer default rating of BBB with a stable outlook.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences have been written to /home/ssever/contradictory-information/src/Data/all_sentences.\n"
     ]
    }
   ],
   "source": [
    "# Store all sentences in text file\n",
    "\n",
    "\"\"\"\n",
    "# filepath = \"/home/ssever/contradictory-information/data/all_sentences\"\n",
    "\n",
    "# Open the file in write mode ('w') and write each sentence to the file\n",
    "with open(filepath, 'w') as file:\n",
    "    for sentence in flattened_and_cleaned_list:\n",
    "        file.write(sentence + '\\n')  # Add '\\n' to ensure each sentence is on a new line\n",
    "\n",
    "print(f\"Sentences have been written to {filepath}.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21432"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening the file in read mode \n",
    "my_file = open(\"/home/ssever/contradictory-information/data/text_files/all_sentences\", \"r\") \n",
    "\n",
    "# reading the file \n",
    "all_sentences = my_file.read()\n",
    "all_sentences = all_sentences.split('\\n')\n",
    "\n",
    "my_file.close()\n",
    "\n",
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered sentences: 16889\n"
     ]
    }
   ],
   "source": [
    "# Extract all sentences in token length between 10 and 45\n",
    "\n",
    "filtered_sentences = [sentence for sentence in all_sentences if len(nltk.word_tokenize(sentence)) <= 45 and len(nltk.word_tokenize(sentence)) >= 10]\n",
    "print(f\"Number of filtered sentences:\", len(filtered_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file = open(\"/home/ssever/contradictory-information/data/text_files/random_sentences\", \"r\") \n",
    "\n",
    "# reading the file \n",
    "random_sentences = my_file.read()\n",
    "random_sentences = random_sentences.split('\\n')\n",
    "\n",
    "my_file.close()\n",
    "\n",
    "len(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_sentences = [s for s in filtered_sentences if s not in random_sentences]\n",
    "structure_sentences = structure_sentences[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Extract sentences that contain numerical values\n",
    "\n",
    "import re\n",
    "sentences_with_numbers = [sentence for sentence in filtered_sentences if re.search(r'\\d', sentence)]\n",
    "\n",
    "pattern = re.compile(r'â‚¬|euro|%|percentage|million|billion|thousand', re.IGNORECASE)\n",
    "\n",
    "sentences_with_numbers = [sentence for sentence in sentences_with_numbers if pattern.search(sentence)]\n",
    "len(sentences_with_numbers)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3000 random sentences for pair generation\n",
    "#random_sentences = random.sample(filtered_sentences, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sentence with the least amount of tokens\n",
    "\n",
    "min_tokens = float('inf')\n",
    "sentence_with_least_tokens = \"\"\n",
    "\n",
    "for sentence in filtered_sentences:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    if len(tokens) < min_tokens:\n",
    "        min_tokens = len(tokens)\n",
    "        sentence_with_least_tokens = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence with the most tokens: \"The Supervisory Board believes the proposed dividend is appropriate.\"\n",
      "Number of tokens: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence with the most tokens: \\\"{sentence_with_least_tokens}\\\"\")\n",
    "print(f\"Number of tokens: {min_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create pairs for training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize gpt api\n",
    "#openai.api_key = (\"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\") # Genow AI Key\n",
    "openai.api_key = (\"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\") # Lehrstuhl Key\n",
    "model= 'gpt-4-turbo-preview'\n",
    "max_tokens = 1024\n",
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category types used for pair generation\n",
    "category_types = [structure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose sentences for category pair generation\n",
    "#train_premises = random_sentences[1500:]\n",
    "\n",
    "#train_premises = numeric_sentences[80:]\n",
    "\n",
    "train_premises = structure_sentences[148:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of new contradictions to generate for each type\n",
    "num_hypotheses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main cell: Contains prompt for pair generation and thus generates all pairs for the NLI dataset\"\"\"\n",
    "\n",
    "all_responses=[]\n",
    "\n",
    "num_index = len(category_types)\n",
    "index = 0\n",
    "\n",
    "for premise in train_premises:\n",
    "    if index == num_index:\n",
    "            index = 0\n",
    "    response=[]\n",
    "    res = openai.ChatCompletion.create(\n",
    "              model=model,\n",
    "              max_tokens=max_tokens,\n",
    "              temperature = temperature,\n",
    "              messages=[{\"role\": \"system\", \"content\": \"You are an expert on semantics and linguistics, with a profound knowledge\\\n",
    " in Natural Language Processing. You are especially aware of structural contradictions. To this end, A structural contradiction means that a contradiction arises\\\n",
    " between two statements (Premise and Hypothesis) because there is a mismatch in the sentence structure. The contradiction only changes the sentence structure.\\\n",
    " Don't change or add anything to the verb of the sentence. Don't change the subject of the phrase. Only change the object or the subject of the phrase.\\\n",
    " The premise is provided, you have to create a hypothesis for a structural mismatch for this premise.\"},\n",
    " {\"role\": \"user\", \"content\": f\"Please generate a structural mismatch hypothesis for a {premise}, based on {category_types[index].description}. An example of a structural mismatch is given in {category_types[index].instances}\\\n",
    " Format your response in the following way: {category_types[index].name} P: [PREMISE]. H: [HYPOTHESIS]. Make sure to include {category_types[index].name}\"},\n",
    " {\"role\": \"assistant\", \"content\": category_types[index].description}],\n",
    "        )\n",
    "\n",
    "    #print(res[\"choices\"][0][\"message\"][\"content\"])\n",
    "    response.append(res[\"choices\"][0][\"message\"][\"content\"])\n",
    "    index += 1\n",
    "    time.sleep(2)\n",
    "        #contradiction = [res[\"choices\"][0][\"message\"][\"content\"]]\n",
    "        #response.append(contradiction)\n",
    "    if response not in all_responses:\n",
    "        all_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all next line characters in sentence pairs\n",
    "cleaned_sentences = [[s.replace('\\n', ' ') for s in sublist] for sublist in all_responses]\n",
    "len(cleaned_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contradiction prompt:\n",
    "\n",
    "[{\"role\": \"system\", \"content\": \"You are an expert on semantics and linguistics, with a profound knowledge\\\n",
    "in Natural Language Processing. You are especially aware of the work by Marneffe et al., classifying\\\n",
    "different types of contradictions, such as antonyms, negations, numerical mismatches, factive, structural, lexical, and world knowledge contradictions. To this end,\\\n",
    "a contradiction is defined as a mismatch between two statements, such that they cannot possibly both be true.\\\n",
    "It is assumed, that both statements refer to the same fact or event, even if this is not explicitly stated.The Premise is provided,\\\n",
    "you have to create a Hypothesis of one of the contradiction types for this premise.\"},\n",
    "{\"role\": \"user\", \"content\": f\"Please generate one contradictory hypothesis for a {premise}, based on {category_types[index].description}. The contradictions\\\n",
    "should be original and reasonably different from each other.\\\n",
    "Format your response in the following way: {category_types[index].name} P: [PREMISE]. H: [HYPOTHESIS]. Make sure to include {category_types[index].name}\"},\n",
    "{\"role\": \"assistant\", \"content\": category_types[index].description},]\n",
    "\n",
    "# entailment, neutral prompt:\n",
    "\n",
    "[{\"role\": \"system\", \"content\": \"You are an expert on semantics and linguistics, with a profound knowledge\\\n",
    "in Natural Language Processing. You are aware of the work of classifying entailments and neutral pairs of statements. To this end,\\\n",
    "an entailment is defined in that two statements are entailed if the truth of the second statement follows from the truth of the first statement.\\\n",
    "Statements of neutral pairs do neither entail nor contradict each other.\\\n",
    "In the case of entailment it is assumed, that both statements refer to the same fact or event, even if this is not explicitly stated.\\\n",
    "The Premise is provided, you have to create a hypothesis for this premise.\"},\n",
    "{\"role\": \"user\", \"content\": f\"Please generate one hypothesis for a {premise}, based on {category_types[index].description}. The hypotheses\\\n",
    "should be original and reasonably different from each other.\\\n",
    "Format your response in the following way: {category_types[index].name} P: [PREMISE]. H: [HYPOTHESIS]. Make sure to include {category_types[index].name}\"},\n",
    "{\"role\": \"assistant\", \"content\": category_types[index].description},]\n",
    "\n",
    "# numeric mimsatch prompt:\n",
    "\n",
    "[{\"role\": \"system\", \"content\": \"You are an expert on semantics and linguistics, with a profound knowledge\\\n",
    " in Natural Language Processing. You are especially aware of contradictions, such as numerical mismatches. To this end, A contradiction based on a numerical mismatch means that a contradiction arises\\\n",
    " between two statements (Premise and Hypothesis) because there are mismatching numbers in premise and hypothesis. The contradiction only changes the numerical values. Don't change anything else in the text.\\\n",
    " The premise is provided, you have to create a hypothesis for a numerical mismatch for this premise.\"},\n",
    " {\"role\": \"user\", \"content\": f\"Please generate numerical mismatch hypothesis for a {premise}, based on {category_types[index].description}.\\\n",
    " Format your response in the following way: {category_types[index].name} P: [PREMISE]. H: [HYPOTHESIS]. Make sure to include {category_types[index].name}\"},\n",
    " {\"role\": \"assistant\", \"content\": category_types[index].description},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences have been written to /home/ssever/contradictory-information/src/Data/text_files/first_numeric_pairs.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Specify the filename\n",
    "filepath = \"/home/ssever/contradictory-information/data/text_files/first_numeric_pairs\"\n",
    "\n",
    "# Open the file in write mode ('w') and write each sentence to the file\n",
    "with open(filepath, 'w') as file:\n",
    "    for sentence in cleaned_sentences:\n",
    "        for s in sentence:\n",
    "            file.write(s + '\\n')  # Add '\\n' to ensure each sentence is on a new line\n",
    "\n",
    "print(f\"Sentences have been written to {filepath}.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1480"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to your file\n",
    "file_path = '/home/ssever/contradictory-information/data/text_files/first_pairs'\n",
    "\n",
    "# Initialize an empty list to hold the elements\n",
    "elements_list = []\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read each line in the file\n",
    "    for line in file:\n",
    "        # Strip the newline character and add the line to the list\n",
    "        elements_list.append(line.strip())\n",
    "\n",
    "# Now elements_list contains all the elements from the file\n",
    "len(elements_list)\n",
    "\n",
    "count_list = []\n",
    "for item in elements_list:\n",
    "    if not item.startswith('P'):\n",
    "        count_list.append(item)\n",
    "\n",
    "len(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ssever/contradictory-information/data/text_files/structure_pairs\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # Read all lines into a list, stripping the newline character from each line\n",
    "    sentences = [line.strip() for line in file]\n",
    "\n",
    "# Now 'sentences' contains each line of the file as an element in the list\n",
    "sentences = [[sentence] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Store pairs in csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Split sentence pairs into premise, hypothesis and label\n",
    "\n",
    "split_data = []\n",
    "for item in sentences:\n",
    "    for i in item:\n",
    "        if not i.startswith('P'):\n",
    "            parts = i.split(' P: ')\n",
    "            label = parts[0]\n",
    "            premise_hypothesis = parts[1].split(' H: ')\n",
    "            premise = premise_hypothesis[0]\n",
    "            hypothesis = premise_hypothesis[1]\n",
    "            split_data.append([premise, hypothesis, label])\n",
    "\n",
    "with open('/home/ssever/contradictory-information/data/csv_files/structure.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"premise\", \"hypothesis\", \"label\"])\n",
    "    writer.writerows(split_data[:167])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine contradictions CSV file with entailment and neutral CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /home/ssever/contradictory-information/src/Data/csv_files/combined_data_set.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "file1_path = '/home/ssever/contradictory-information/data/csv_files/gpt_contradictions.csv'\n",
    "file2_path = '/home/ssever/contradictory-information/data/csv_files/gpt_entail_neutral.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Append the rows of the second dataframe to the first dataframe\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_csv_path = '/home/ssever/contradictory-information/data/csv_files/combined_data_set.csv'\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "print(f'Combined CSV saved to {combined_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clean and transform csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add unique IDs to dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Function to generate a unique alphanumeric id\n",
    "def generate_unique_id(length=10):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# CSV is loaded into a DataFrame\n",
    "df = pd.read_csv('/home/ssever/contradictory-information/data/csv_files/combined_data_set.csv')\n",
    "\n",
    "# Generate uniqze ids\n",
    "unique_ids = set()\n",
    "while len(unique_ids) < len(df):\n",
    "    unique_ids.add(generate_unique_id())\n",
    "\n",
    "# Insert ids into table\n",
    "df.insert(0, 'id', list(unique_ids))\n",
    "\n",
    "# make all labels lowercase\n",
    "df['label'] = df['label'].str.lower()\n",
    "\n",
    "# align elements to the left\n",
    "styled_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "styled_df.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "\n",
    "# Insert into CSV file\n",
    "df.to_csv('/home/ssever/contradictory-information/data/csv_files/combined_data_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change label string values to numeric values\n",
    "\n",
    "df = pd.read_csv('/home/ssever/contradictory-information/data/csv_files/combined_data_set.csv')\n",
    "\n",
    "# Strip leading and trailing spaces from the 'label' column\n",
    "df['label'] = df['label'].str.strip()\n",
    "\n",
    "# Identify unique words and sort them to maintain consistency\n",
    "unique_words = sorted(df['label'].unique())\n",
    "\n",
    "# Create a mapping from words to digits\n",
    "word_to_digit = {word: i for i, word in enumerate(unique_words)}\n",
    "\n",
    "# Apply the mapping to the 'label' column\n",
    "df['label_digit'] = df['label'].map(word_to_digit)\n",
    "\n",
    "# Rename the original 'label' column to 'label_string'\n",
    "df.rename(columns={'label': 'label_string', 'label_digit': 'label'}, inplace=True)\n",
    "\n",
    "# Adjusting the column order, ensuring 'label_string' is positioned next to 'label'\n",
    "columns_order = ['id', 'premise', 'hypothesis', 'label', 'label_string'] + [col for col in df.columns if col not in ['id', 'premise', 'hypothesis', 'label', 'label_string']]\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV\n",
    "shuffled_df.to_csv('/home/ssever/contradictory-information/data/csv_files/nli_data_set.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
