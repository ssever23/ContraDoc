{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# Store\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Language model\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset, TensorDataset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Additional libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load and split new document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 400, chunk_overlap = 100, add_start_index = False) # splits the text into chunks\n",
    "loader = PyPDFLoader(\"/home/user123/contradictory-information/data/Inject/Press_release_q1_2024.pdf\").load()\n",
    "split_text = text_splitter.split_documents(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inject_content = [doc.page_content for doc in split_text]\n",
    "print(f\"Number of chunks in new document: {len(inject_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Similarity search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding and vector store\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "db = Chroma(persist_directory=\"/home/user123/contradictory-information/src/vectorization/vector_store/kb_langchain\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_chunks = []\n",
    "k = 2\n",
    "for chunk in inject_content:\n",
    "    docs = db.similarity_search_with_score(chunk, k=k)\n",
    "    #print(docs[0][1])\n",
    "    #if docs[0][1] <= 0.5:\n",
    "    #    print(docs[0][0])\n",
    "\n",
    "    for doc, score in docs:\n",
    "        knowledge_chunks.append(doc.page_content)\n",
    "\n",
    "(f\"Number of similar chunks in knowledge base: {len(knowledge_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create and clean pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each premise\n",
    "cleaned_premises = [\n",
    "    re.sub(r'\\s+\\.', '.',  # Remove space before period\n",
    "           re.sub(r'\\s+,', ',',  # Remove space before comma\n",
    "                  re.sub(r'\\n', '', chunk)))  # Remove new lines\n",
    "    for chunk in inject_content]\n",
    "\n",
    "sentences_premises = [sent_tokenize(text) for text in cleaned_premises]\n",
    "len(sentences_premises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each hypothesis\n",
    "cleaned_hypotheses = [\n",
    "    re.sub(r'\\s+\\.', '.',  # Remove space before period\n",
    "           re.sub(r'\\s+,', ',',  # Remove space before comma\n",
    "                  re.sub(r'\\n', '', chunk)))  # Remove new lines\n",
    "    for chunk in knowledge_chunks]\n",
    "\n",
    "sentences_hypotheses = [sent_tokenize(text) for text in cleaned_hypotheses]\n",
    "len(sentences_hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combination of each sentence on one chunk for each sentence in the corresponding chunk\n",
    "#similar_pairs = [list(itertools.product(sentences_premises[k], sentences_hypotheses[k])) for k in range(0, len(sentences_premises))]\n",
    "#similar_pairs = list(itertools.chain.from_iterable(similar_pairs)) # de-nest list of lists\n",
    "\n",
    "#print(f\"Number of sentence pairs: {len(similar_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combination of each sentence on one chunk for each sentence in the corresponding chunk\n",
    "similar_pairs = []\n",
    "num_pairs = k\n",
    "# Loop through the sentence_premises\n",
    "for i in range(len(sentences_premises)):\n",
    "    # Create pairs for the specified number of corresponding strings from sentence_hypothesis\n",
    "    for j in range(num_pairs):\n",
    "        # Check to prevent index out of range error\n",
    "        if num_pairs * i + j < len(sentences_hypotheses):\n",
    "            pair = list(itertools.product(sentences_premises[i], sentences_hypotheses[num_pairs*i + j]))\n",
    "            similar_pairs.append(pair)\n",
    "\n",
    "similar_pairs = list(itertools.chain.from_iterable(similar_pairs)) # de-nest list of lists\n",
    "print(f\"Number of sentence pairs: {len(similar_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classification of pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device type:', device)\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print('GPU is:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/user123/contradictory-information/model/roberta-base.pt'\n",
    "#model_path = '/home/user123/contradictory-information/model/xlm-roberta-base-snli-mnli-anli-xnli.pt'\n",
    "#model_path = '/home/user123/contradictory-information/model/roberta-large.pt'\n",
    "\n",
    "tokenizer_path = 'roberta-base'\n",
    "#tokenizer_path = 'symanto/xlm-roberta-base-snli-mnli-anli-xnli'\n",
    "#tokenizer_path = 'roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = torch.load(model_path)\n",
    "model.to(device)\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Function for encoding input data\n",
    "def encode_sets(data, tokenizer):\n",
    "    kwargs = { 'truncation': True,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'padding': 'max_length',\n",
    "    'return_attention_mask': True, \n",
    "    'return_token_type_ids': True     \n",
    "    }\n",
    "    #datalist = list(zip(data['premise'], data['hypothesis']))\n",
    "    tokenized = tokenizer.batch_encode_plus(data,**kwargs)\n",
    "    input_ids = torch.LongTensor(tokenized.input_ids)\n",
    "    attention_masks = torch.LongTensor(tokenized.attention_mask)\n",
    "    token_type_ids = torch.LongTensor(tokenized.token_type_ids)\n",
    "    return input_ids, attention_masks, token_type_ids\n",
    "\n",
    "\n",
    "# Encode similar pairs\n",
    "input_ids, attention_masks, token_type_ids = encode_sets(similar_pairs, tokenizer)\n",
    "pairs_tensor = TensorDataset(input_ids, attention_masks, token_type_ids)\n",
    "pairs_dataloader = DataLoader(pairs_tensor, sampler=SequentialSampler(pairs_tensor), batch_size=len(similar_pairs))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in pairs_dataloader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_masks, token_type_ids = (batch[0].to(device), \n",
    "                                                      batch[1].to(device),\n",
    "                                                      batch[2].to(device))\n",
    "        start_time = time.time()\n",
    "        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_masks)\n",
    "        end_time = time.time()\n",
    "\n",
    "    logits = outputs.logits\n",
    "    model_preds = logits.detach().cpu().numpy()\n",
    "\n",
    "    # Calculate inference time\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"\\nInference time: {inference_time:.4f} seconds\\n\")\n",
    "    predictions = np.argmax(model_preds, axis=1)\n",
    "\n",
    "# target names according to 3 label or 11 label model\n",
    "if model_path == '/home/user123/contradictory-information/model/xlm-roberta-base-snli-mnli-anli-xnli.pt':\n",
    "    target_names = [\n",
    "    \"entailment\",\n",
    "    \"neutral\",\n",
    "    \"contradiction\"\n",
    "]\n",
    "else:\n",
    "    target_names = [\n",
    "    \"antonymity\",\n",
    "    \"entailment\",\n",
    "    \"factive_antonymity\",\n",
    "    \"factive_embedding_verb\",\n",
    "    \"lexical\",\n",
    "    \"negation\",\n",
    "    \"neutral\",\n",
    "    \"numeric\",\n",
    "    \"structure\",\n",
    "    \"temporal\",\n",
    "    \"worldknowledge\"\n",
    "]\n",
    "    \n",
    "# Use Counter to count occurrences\n",
    "count = {target_names[key]: value for key, value in Counter(predictions).items()}\n",
    "\n",
    "# Printing the count of each number\n",
    "print(f\"Predictions:\\n{count}\")\n",
    "\n",
    "# count all predicted labels\n",
    "total_count = sum(count.values())\n",
    "\n",
    "# check whether label entailment has been predicted at least once and count the amount\n",
    "if 'entailment' in count.keys():\n",
    "    entailment_share = (count[\"entailment\"] / total_count) * 100\n",
    "else:\n",
    "    entailment_share = 0\n",
    "\n",
    "# check whether label neutral has been predicted at least once and count the amount\n",
    "if 'neutral' in count.keys():\n",
    "    neutral_share = (count[\"neutral\"] / total_count) * 100\n",
    "else:\n",
    "    neutral_share = 0\n",
    "\n",
    "# check whether a contradiction label has been predicted at least once count the amount\n",
    "keys = {'entailment', 'neutral'}\n",
    "contradiction_keys = set(count.keys()) - keys\n",
    "if contradiction_keys:\n",
    "    contradiction_labels =  [label for label in count if label not in [\"entailment\", \"neutral\"]]\n",
    "    contradiction_count = sum(count[label] for label in contradiction_labels)\n",
    "    contradiction_share = (contradiction_count / total_count) * 100\n",
    "else:\n",
    "    contradiction_share = 0\n",
    "\n",
    "print(f\"\\nDistribution:\\nEntailment: {entailment_share:.2f}%, Neutral: {neutral_share:.2f}%, Contradictions: {contradiction_share:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probabilty for each predicted class\n",
    "probabilities = softmax(logits, dim=1)\n",
    "#probabilities = [[round(max(value), 5), target_names[value.index(max(value))]] for value in probabilities.tolist()]\n",
    "probabilities = [round(max(value), 2) for value in probabilities.tolist()]\n",
    "\n",
    "# join pairs with label and probability\n",
    "labels = [target_names[number] for number in predictions]\n",
    "classifications = list(zip(similar_pairs, labels))\n",
    "list(zip(classifications, probabilities))\n",
    "contradictions = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities)) if label != 'entailment' and label != 'neutral']\n",
    "classifications = [[label, premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities))]\n",
    "for number, pair in enumerate(classifications):\n",
    "    print(number, pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_contradictions = [['Group revenue in the first quarter of 2024 grew by 2.8 percent to € 2.859 billion yearon-year (Q1 2023: € 2.781 billion).','Group revenue in the first quarter of 2024 grew by 5.4 percent to € 2.859 billion yearon-year (Q1 2023: € 2.781 billion).', 'numeric'],\n",
    "                         ['In the Industrial Trucks & Services segment, revenue increased by 7.4 percent to € 2.153 billion (Q1 2023: € 2.005 billion), mainly due to the positive geographic and product mix as well as higher production output and sales prices. The service business also grew.', 'In the Industrial Trucks & Services segment, revenue decreased by 7.4 percent to € 2.153 billion (Q1 2023: € 2.005 billion), mainly due to the negative geographic and product mix as well as higher production output and sales prices.', 'antonymity'],\n",
    "                         ['This was mainly due to the continued stability of material purchase prices, increased productivity as a result of improved material availability and revenue growth.', 'This was to a small degree due to the continued stability of material purchase prices, increased productivity as a result of improved material availability and revenue growth.', 'factive_antonymity'],\n",
    "                         ['The KION Group is one of the world’s leading providers of industrial trucks and supply chain solutions.','The KION Group has removed industrial trucks from its product portfolio and focuses on supply chain solutions.', 'worldknowledge'],\n",
    "                         ['Based on revenue for the year 2022, the KION Group is the leading overseas manufacturer in China, and including domestic manufacturers, the third-largest supplier there.', 'Based on revenue for the year 2022, the KION Group is the leading overseas manufacturer in China, and including domestic manufacturers, the second-largest supplier there.','structure'],\n",
    "                         ['The KION Group is also one of the world’s leading warehouse automation providers, based on 2022 revenue.','The KION Group has lost its leading position as a warehouse automation provider, based on 2022 revenue.','factive_embedding_verb'],\n",
    "                         ['At the end of 2023, more than 1.8 million industrial trucks of the KION Group were in use by customers from all manner of sectors and of varying sizes on six continents.','At the end of 2023, more than 1.8 million industrial trucks of the KION Group were in use by customers from a small number of sectors and of same sizes on six continents.','lexical'],\n",
    "                         ]\n",
    "\n",
    "reverse = [[hypothesis] for [premise, hypothesis, label] in manual_contradictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_contradictions = [['temporal', 'EBIT  margin of  7.9 percent  (Q1 2023: 5.6 percent)  \\uf0a7 Positive  free cash flow of € 65.7 million  (Q1 2023: € 104.9 million ) \\uf0a7 Full year 2024 outlook confirmed   Frankfurt am Main, April 25th,  2024  – The KION Group started the financial year 2024 with revenue  growth and improved  profitability.', 'Frankfurt am Main, April 25th, 2024 – The KION Group just finished  the financial year 2024 and started 2025 with revenue growth and improved profitability.'],\n",
    "    \n",
    "['numeric', 'Group revenue in the first quarter of 2024 grew by 2.8 percent to € 2.859 billion year -on-year (Q1 2023: € 2.781 billion).', 'Group revenue in the first quarter of 2024 grew by 5.4 percent  to € 2.859 billion year - on-year ( Q1 2023: € 2.781 billion).'],\n",
    "\n",
    "['structure', 'In the Industrial Trucks & Services  segment, revenue increased by 7.4 percent  to € 2.153 billion ( Q1 2023: € 2.005 billion), mainly due to the positive geographic and product mix as well as  higher  production output  and', 'In the Industrial Trucks & Services segment,  revenue decreased  by 7.4 percent to € 2.153 billion ( Q1 2023: € 2.005 billion), mainly'],\n",
    "\n",
    "['negation', 'The Supply Chain Solutions segment benefited from increased  demand from pure e -commerce providers, general merchandise,  and food retailers, but order intake in the project business  remained subdued in the first three months impacted by customers’', 'The Supply Chain Solutions segment did not benefit  from increased demand from pure e - commerce providers, general merchandise, and food retailers, but order'],\n",
    "\n",
    "['structure', 'This was mainly due to the continued stability of material purchase prices, increased productivity as a result of improved  material availability and revenue growth.', 'This was  to a small degree  due to the continued stability of material  purchase prices, increased productivity as a result of improved material'],\n",
    "\n",
    "['worldknowledge', 'The Company  The KION Group is one of the world’s leading providers of industrial trucks and supply', 'The Company   The KION Group has removed industrial trucks from its product portfolio and focuses'],\n",
    "\n",
    "['structure', 'the KION Group is the leading overseas manufacturer in China, and including domestic manufacturers, the third- largest supplier there.', 'the KION Group is the leading overseas manufacturer in China, and including domestic  manufacturers, the second -largest  supplier there.'],\n",
    "\n",
    "['negation', 'The KION Group is also one of the world’s leading warehouse automation providers, based on 2022  revenue.', 'The KION Group has lost its leading position as a warehouse automation provider, based on 2022 revenue.'],\n",
    "\n",
    "['entailment', 'At the end of 2023, more than 1.', 'At the end of 2023, more than 1.8 million industrial trucks of the KION Group were in  use by customers from a  small number  of sectors and of same  sizes on six continents.'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_contradictions = [[premise, hypothesis, label] for [label, premise, hypothesis] in my_contradictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Store results in persistent variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_sentences = my_contradictions\n",
    "%store langchain_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluation graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "categories = ['A', 'B', 'C', 'D', 'E']\n",
    "values = [25, 16, 23, 13, 19]\n",
    "\n",
    "# Creating the bar diagram\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(categories, values, color='blue')\n",
    "plt.title('Bar Diagram')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Search for source document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "check = Chroma(persist_directory=\"/home/user123/contradictory-information/src/vectorization/vector_store/kb_langchain\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'The adjusted EBIT margin of 7.9 percent came in  2.3 percentage points higher year -on-year, with significant improvements in both operating segments.'\n",
    "\n",
    "check.similarity_search(query, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['negation', 'The Supply Chain Solutions segment benefited from increased  demand from pure e -commerce providers, general merchandise,  and food retailers, but order intake in the project business  remained subdued in the first three months impacted by customers’', 'The Supply Chain Solutions segment did not benefit  from increased demand from pure e - commerce providers, general merchandise, and food retailers, but order']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
