{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# Store\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Language model\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset, TensorDataset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Additional libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load and split new document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 400, chunk_overlap = 100, add_start_index = False) # splits the text into chunks\n",
    "loader = PyPDFLoader(\"/home/ssever/ContraDoc/data/Inject/Press_release_q1_2024.pdf\").load()\n",
    "split_text = text_splitter.split_documents(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [doc.page_content for doc in split_text]\n",
    "print(f\"Number of chunks in new document: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Similarity search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "db = Chroma(persist_directory=\"/home/ssever/ContraDoc/src/vectorization/vector_store/no_kb_langchain\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_chunks = []\n",
    "k = 1\n",
    "for chunk in chunks:\n",
    "    docs = db.similarity_search_with_score(chunk, k=k)\n",
    "    #print(docs[0][1])\n",
    "    #if docs[0][1] <= 0.5:\n",
    "    #    print(docs[0][0])\n",
    "\n",
    "    for doc, score in docs:\n",
    "        knowledge_chunks.append(doc.page_content)\n",
    "\n",
    "(f\"Number of similar chunks in knowledge base: {len(knowledge_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create and clean pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each premise\n",
    "cleaned_premises = [\n",
    "    re.sub(r'\\s+\\.', '.',  # Remove space before period\n",
    "           re.sub(r'\\s+,', ',',  # Remove space before comma\n",
    "                  re.sub(r'\\n', '', chunk)))  # Remove new lines\n",
    "    for chunk in chunks]\n",
    "\n",
    "print(len(cleaned_premises))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each hypothesis\n",
    "cleaned_hypotheses = [\n",
    "    re.sub(r'\\s+\\.', '.',  # Remove space before period\n",
    "           re.sub(r'\\s+,', ',',  # Remove space before comma\n",
    "                  re.sub(r'\\n', '', chunk)))  # Remove new lines\n",
    "    for chunk in knowledge_chunks]\n",
    "\n",
    "print(len(cleaned_hypotheses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar_pairs = list(zip(cleaned_premises, cleaned_hypotheses))\n",
    "#print(f\"Number of chunk pairs: {len(similar_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result list\n",
    "similar_pairs = []\n",
    "num_pairs = k\n",
    "# Loop through the first list\n",
    "for i in range(len(cleaned_premises)):\n",
    "    # Create pairs for the specified number of corresponding strings from list2\n",
    "    for j in range(num_pairs):\n",
    "        pair = (cleaned_premises[i], cleaned_hypotheses[num_pairs*i + j])\n",
    "        similar_pairs.append(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classification of pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device type:', device)\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print('GPU is:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/ssever/ContraDoc/model/roberta-base.pt'\n",
    "#model_path = '/home/ssever/ContraDoc/model/xlm-roberta-base-snli-mnli-anli-xnli.pt'\n",
    "#model_path = '/home/ssever/ContraDoc/model/roberta-large.pt'\n",
    "\n",
    "tokenizer_path = 'roberta-base'\n",
    "#tokenizer_path = 'symanto/xlm-roberta-base-snli-mnli-anli-xnli'\n",
    "#tokenizer_path = 'roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = torch.load(model_path)\n",
    "model.to(device)\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Function for encoding input data\n",
    "def encode_sets(data, tokenizer):\n",
    "    kwargs = { 'truncation': True,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'padding': 'max_length',\n",
    "    'return_attention_mask': True, \n",
    "    'return_token_type_ids': True     \n",
    "    }\n",
    "    #datalist = list(zip(data['premise'], data['hypothesis']))\n",
    "    tokenized = tokenizer.batch_encode_plus(data,**kwargs)\n",
    "    input_ids = torch.LongTensor(tokenized.input_ids)\n",
    "    attention_masks = torch.LongTensor(tokenized.attention_mask)\n",
    "    token_type_ids = torch.LongTensor(tokenized.token_type_ids)\n",
    "    return input_ids, attention_masks, token_type_ids\n",
    "\n",
    "\n",
    "# Encode similar pairs\n",
    "input_ids, attention_masks, token_type_ids = encode_sets(similar_pairs, tokenizer)\n",
    "pairs_tensor = TensorDataset(input_ids, attention_masks, token_type_ids)\n",
    "pairs_dataloader = DataLoader(pairs_tensor, sampler=SequentialSampler(pairs_tensor), batch_size=len(similar_pairs))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in pairs_dataloader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_masks, token_type_ids = (batch[0].to(device), \n",
    "                                                      batch[1].to(device),\n",
    "                                                      batch[2].to(device))\n",
    "        start_time = time.time()\n",
    "        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_masks)\n",
    "        end_time = time.time()\n",
    "\n",
    "    logits = outputs.logits\n",
    "    model_preds = logits.detach().cpu().numpy()\n",
    "\n",
    "    # Calculate inference time\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"\\nInference time: {inference_time:.4f} seconds\\n\")\n",
    "    predictions = np.argmax(model_preds, axis=1)\n",
    "\n",
    "# target names according to 3 label or 11 label model\n",
    "if model_path == '/home/ssever/ContraDoc/model/xlm-roberta-base-snli-mnli-anli-xnli.pt':\n",
    "    target_names = [\n",
    "    \"entailment\",\n",
    "    \"neutral\",\n",
    "    \"contradiction\"\n",
    "]\n",
    "else:\n",
    "    target_names = [\n",
    "    \"antonym\",\n",
    "    \"entailment\",\n",
    "    \"factive_antonym\",\n",
    "    \"factive_embedding_verb\",\n",
    "    \"lexical\",\n",
    "    \"negation\",\n",
    "    \"neutral\",\n",
    "    \"numeric\",\n",
    "    \"structure\",\n",
    "    \"temporal\",\n",
    "    \"worldknowledge\"\n",
    "]\n",
    "    \n",
    "# Use Counter to count occurrences\n",
    "count = {target_names[key]: value for key, value in Counter(predictions).items()}\n",
    "\n",
    "# Printing the count of each number\n",
    "print(f\"Predictions:\\n{count}\")\n",
    "\n",
    "# count all predicted labels\n",
    "total_count = sum(count.values())\n",
    "\n",
    "# check whether label entailment has been predicted at least once and count the amount\n",
    "if 'entailment' in count.keys():\n",
    "    entailment_share = (count[\"entailment\"] / total_count) * 100\n",
    "else:\n",
    "    entailment_share = 0\n",
    "\n",
    "# check whether label neutral has been predicted at least once and count the amount\n",
    "if 'neutral' in count.keys():\n",
    "    neutral_share = (count[\"neutral\"] / total_count) * 100\n",
    "else:\n",
    "    neutral_share = 0\n",
    "\n",
    "# check whether a contradiction label has been predicted at least once count the amount\n",
    "keys = {'entailment', 'neutral'}\n",
    "contradiction_keys = set(count.keys()) - keys\n",
    "if contradiction_keys:\n",
    "    contradiction_labels =  [label for label in count if label not in [\"entailment\", \"neutral\"]]\n",
    "    contradiction_count = sum(count[label] for label in contradiction_labels)\n",
    "    contradiction_share = (contradiction_count / total_count) * 100\n",
    "else:\n",
    "    contradiction_share = 0\n",
    "\n",
    "print(f\"\\nDistribution:\\nEntailment: {entailment_share:.2f}%, Neutral: {neutral_share:.2f}%, Contradictions: {contradiction_share:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probabilty for each predicted class\n",
    "probabilities = softmax(logits, dim=1)\n",
    "#probabilities = [[round(max(value), 5), target_names[value.index(max(value))]] for value in probabilities.tolist()]\n",
    "probabilities = [round(max(value), 2) for value in probabilities.tolist()]\n",
    "\n",
    "# join pairs with label and probability\n",
    "labels = [target_names[number] for number in predictions]\n",
    "classifications = list(zip(similar_pairs, labels))\n",
    "list(zip(classifications, probabilities))\n",
    "entailment_neutral = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities)) if label == 'entailment' or label == 'neutral']\n",
    "#contradictions = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities)) if label != 'entailment' and label != 'neutral']\n",
    "#classifications = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities))]\n",
    "#for number, pair in enumerate(contradictions):\n",
    "#    print(number, pair)\n",
    "print(len(entailment_neutral))\n",
    "#print(len(contradictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Store results in persistent variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chunks = [[premise, hypothesis, label] for [[probability, label], premise, hypothesis] in entailment_neutral]\n",
    "#langchain_chunks = [[premise, hypothesis, label] for [[probability, label], premise, hypothesis] in contradictions]\n",
    "%store langchain_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluation graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "categories = ['A', 'B', 'C', 'D', 'E']\n",
    "values = [6, 2, 0, 6, 5]\n",
    "\n",
    "# Creating the bar diagram\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(categories, values, color='blue')\n",
    "plt.title('Bar Diagram')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
