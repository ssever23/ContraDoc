{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# Store\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Language model\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset, TensorDataset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Additional libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load and split new document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/home/user123/contradictory-information/data/Inject/Press_release_q1_2024.pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = [loader[k].page_content for k in range(0, len(loader))]\n",
    "page_content = ' '.join(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(page_content)\n",
    "print(f\"Number of sentences in new document: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Similarity search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "db = Chroma(persist_directory=\"/home/user123/contradictory-information/src/vectorization/vector_store/no_kb_custom_sentences\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_chunks = []\n",
    "k = 1\n",
    "for sentence in sentences:\n",
    "    docs = db.similarity_search_with_score(sentence, k=k)\n",
    "    #print(docs[0][1])\n",
    "    #if docs[0][1] <= 0.5:\n",
    "    #    print(docs[0][0])\n",
    "\n",
    "    for doc, score in docs:\n",
    "        knowledge_chunks.append(doc.page_content)\n",
    "\n",
    "(f\"Number of similar chunks in knowledge base: {len(knowledge_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create and clean pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each premise\n",
    "cleaned_premises = [\n",
    "    re.sub(r'\\s+\\.', '.',  # Remove space before period\n",
    "           re.sub(r'\\s+,', ',',  # Remove space before comma\n",
    "                  re.sub(r'\\n', '', sentence)))  # Remove new lines\n",
    "    for sentence in sentences]\n",
    "\n",
    "print(len(cleaned_premises))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each hypothesis\n",
    "cleaned_hypotheses = [\n",
    "    re.sub(r'\\s+\\.', '.',  # Remove space before period\n",
    "           re.sub(r'\\s+,', ',',  # Remove space before comma\n",
    "                  re.sub(r'\\n', '', chunk)))  # Remove new lines\n",
    "    for chunk in knowledge_chunks]\n",
    "\n",
    "print(len(cleaned_hypotheses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar_pairs = list(zip(cleaned_premises, cleaned_hypotheses))\n",
    "#print(f\"Number of chunk pairs: {len(similar_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result list\n",
    "similar_pairs = []\n",
    "num_pairs = k\n",
    "# Loop through the first list\n",
    "for i in range(len(cleaned_premises)):\n",
    "    # Create pairs for the specified number of corresponding strings from list2\n",
    "    for j in range(num_pairs):\n",
    "        pair = (cleaned_premises[i], cleaned_hypotheses[num_pairs*i + j])\n",
    "        similar_pairs.append(pair)\n",
    "\n",
    "print(f\"Number of chunk pairs: {len(similar_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_contradictions = [['The KION Group started the financial year 2024 with revenue growth and improved profitability.', 'The KION Group just finished the financial year 2024 and started 2025 with revenue growth and improved profitability.', 'temporal'],\n",
    "                         ['Group revenue in the first quarter of 2024 grew by 2.8 percent to € 2.859 billion yearon-year (Q1 2023: € 2.781 billion).','Group revenue in the first quarter of 2024 grew by 5.4 percent to € 2.859 billion yearon-year (Q1 2023: € 2.781 billion).', 'numeric'],\n",
    "                         ['In the Industrial Trucks & Services segment, revenue increased by 7.4 percent to € 2.153 billion (Q1 2023: € 2.005 billion), mainly due to the positive geographic and product mix as well as higher production output and sales prices. The service business also grew.', 'In the Industrial Trucks & Services segment, revenue decreased by 7.4 percent to € 2.153 billion (Q1 2023: € 2.005 billion), mainly due to the negative geographic and product mix as well as higher production output and sales prices.', 'antonymity'],\n",
    "                         ['The Supply Chain Solutions segment benefited from increased demand from pure ecommerce providers, general merchandise, and food retailers, but order intake in the project business remained subdued in the first three months impacted by customers’ hesitancy to sign new contracts due to macroeconomic uncertainties.', 'The Supply Chain Solutions segment did not benefit from increased demand from pure e-commerce providers, general merchandise, and food retailers, but order intake in the project business remained subdued in the first three months impacted by customers’ hesitancy to sign new contracts due to macroeconomic uncertainties.','negation'],\n",
    "                         ['In addition, the order book contains a higher proportion of short-term projects, whose revenue realization will decrease over a longer period.', 'In addition, the order book contains a higher proportion of long-term projects, whose revenue realization will extend over a longer period.', 'antonymity'],\n",
    "                         ['This was mainly due to the continued stability of material purchase prices, increased productivity as a result of improved material availability and revenue growth.', 'This was to a small degree due to the continued stability of material purchase prices, increased productivity as a result of improved material availability and revenue growth.', 'factive_antonymity'],\n",
    "                         ['The KION Group is one of the world’s leading providers of industrial trucks and supply chain solutions.','The KION Group has removed industrial trucks from its product portfolio and focuses on supply chain solutions.', 'worldknowledge'],\n",
    "                         ['The MDAX listed group is the largest manufacturer of industrial trucks in the EMEA region based on the number of units sold in 2022.','The MDAX listed group is the smallest manufacturer of industrial trucks in the EMEA region based on the number of units sold in 2022.','antonymity'],\n",
    "                         ['Based on revenue for the year 2022, the KION Group is the leading overseas manufacturer in China, and including domestic manufacturers, the third-largest supplier there.', 'Based on revenue for the year 2022, the KION Group is the leading overseas manufacturer in China, and including domestic manufacturers, the second-largest supplier there.','structure'],\n",
    "                         ['The KION Group is also one of the world’s leading warehouse automation providers, based on 2022 revenue.','The KION Group has lost its leading position as a warehouse automation provider, based on 2022 revenue.','factive_embedding_verb'],\n",
    "                         ['At the end of 2023, more than 1.8 million industrial trucks of the KION Group were in use by customers from all manner of sectors and of varying sizes on six continents.','At the end of 2023, more than 1.8 million industrial trucks of the KION Group were in use by customers from a small number of sectors and of same sizes on six continents.','lexical'],\n",
    "                         ['This release and the information contained herein are for information purposes only and do not constitute a prospectus or an offer to sell or a solicitation of an offer to buy any securities in the United States or in any other jurisdiction.','This release and the information contained herein are for information purposes only and do not constitute a prospectus or an offer to sell or a solicitation of an offer to buy any securities in Canada or in any other jurisdiction.','structure'],\n",
    "                         ['Future results could differ significantly from the results that are currently expected due to various risk factors and uncertainties such as changes in economic or industry-specific conditions, changes in the market environment or political situation, changes in domestic or international legislation, interest rate or exchange rate fluctuations, legal disputes and investigations, and the availability of financial resources.', 'Future results will be identical to the results that are currently expected due to various risk factors and uncertainties such as changes in economic or industryspecific conditions, changes in the market environment or political situation, changes in domestic or international legislation, interest rate or exchange rate fluctuations, legal disputes and investigations, and the availability of financial resources.','lexical']\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar_pairs = [[premise, hypothesis] for [premise, hypothesis, label] in manual_contradictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classification of pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device type:', device)\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print('GPU is:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/user123/contradictory-information/model/roberta-base.pt'\n",
    "#model_path = '/home/user123/contradictory-information/model/xlm-roberta-base-snli-mnli-anli-xnli.pt'\n",
    "#model_path = '/home/user123/contradictory-information/model/roberta-large.pt'\n",
    "\n",
    "tokenizer_path = 'roberta-base'\n",
    "#tokenizer_path = 'symanto/xlm-roberta-base-snli-mnli-anli-xnli'\n",
    "#tokenizer_path = 'roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = torch.load(model_path)\n",
    "model.to(device)\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Function for encoding input data\n",
    "def encode_sets(data, tokenizer):\n",
    "    kwargs = { 'truncation': True,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'padding': 'max_length',\n",
    "    'return_attention_mask': True, \n",
    "    'return_token_type_ids': True     \n",
    "    }\n",
    "    #datalist = list(zip(data['premise'], data['hypothesis']))\n",
    "    tokenized = tokenizer.batch_encode_plus(data,**kwargs)\n",
    "    input_ids = torch.LongTensor(tokenized.input_ids)\n",
    "    attention_masks = torch.LongTensor(tokenized.attention_mask)\n",
    "    token_type_ids = torch.LongTensor(tokenized.token_type_ids)\n",
    "    return input_ids, attention_masks, token_type_ids\n",
    "\n",
    "\n",
    "# Encode similar pairs\n",
    "input_ids, attention_masks, token_type_ids = encode_sets(similar_pairs, tokenizer)\n",
    "pairs_tensor = TensorDataset(input_ids, attention_masks, token_type_ids)\n",
    "pairs_dataloader = DataLoader(pairs_tensor, sampler=SequentialSampler(pairs_tensor), batch_size=len(similar_pairs))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in pairs_dataloader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_masks, token_type_ids = (batch[0].to(device), \n",
    "                                                      batch[1].to(device),\n",
    "                                                      batch[2].to(device))\n",
    "        start_time = time.time()\n",
    "        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_masks)\n",
    "        end_time = time.time()\n",
    "\n",
    "    logits = outputs.logits\n",
    "    model_preds = logits.detach().cpu().numpy()\n",
    "\n",
    "    # Calculate inference time\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"\\nInference time: {inference_time:.4f} seconds\\n\")\n",
    "    predictions = np.argmax(model_preds, axis=1)\n",
    "\n",
    "# target names according to 3 label or 11 label model\n",
    "if model_path == '/home/user123/contradictory-information/model/xlm-roberta-base-snli-mnli-anli-xnli.pt':\n",
    "    target_names = [\n",
    "    \"entailment\",\n",
    "    \"neutral\",\n",
    "    \"contradiction\"\n",
    "]\n",
    "else:\n",
    "    target_names = [\n",
    "    \"antonymity\",\n",
    "    \"entailment\",\n",
    "    \"factive_antonymity\",\n",
    "    \"factive_embedding_verb\",\n",
    "    \"lexical\",\n",
    "    \"negation\",\n",
    "    \"neutral\",\n",
    "    \"numeric\",\n",
    "    \"structure\",\n",
    "    \"temporal\",\n",
    "    \"worldknowledge\"\n",
    "]\n",
    "    \n",
    "# Use Counter to count occurrences\n",
    "count = {target_names[key]: value for key, value in Counter(predictions).items()}\n",
    "\n",
    "# Printing the count of each number\n",
    "print(f\"Predictions:\\n{count}\")\n",
    "\n",
    "# count all predicted labels\n",
    "total_count = sum(count.values())\n",
    "\n",
    "# check whether label entailment has been predicted at least once and count the amount\n",
    "if 'entailment' in count.keys():\n",
    "    entailment_share = (count[\"entailment\"] / total_count) * 100\n",
    "else:\n",
    "    entailment_share = 0\n",
    "\n",
    "# check whether label neutral has been predicted at least once and count the amount\n",
    "if 'neutral' in count.keys():\n",
    "    neutral_share = (count[\"neutral\"] / total_count) * 100\n",
    "else:\n",
    "    neutral_share = 0\n",
    "\n",
    "# check whether a contradiction label has been predicted at least once count the amount\n",
    "keys = {'entailment', 'neutral'}\n",
    "contradiction_keys = set(count.keys()) - keys\n",
    "if contradiction_keys:\n",
    "    contradiction_labels =  [label for label in count if label not in [\"entailment\", \"neutral\"]]\n",
    "    contradiction_count = sum(count[label] for label in contradiction_labels)\n",
    "    contradiction_share = (contradiction_count / total_count) * 100\n",
    "else:\n",
    "    contradiction_share = 0\n",
    "\n",
    "print(f\"\\nDistribution:\\nEntailment: {entailment_share:.2f}%, Neutral: {neutral_share:.2f}%, Contradictions: {contradiction_share:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probabilty for each predicted class\n",
    "probabilities = softmax(logits, dim=1)\n",
    "#probabilities = [[round(max(value), 5), target_names[value.index(max(value))]] for value in probabilities.tolist()]\n",
    "probabilities = [round(max(value), 2) for value in probabilities.tolist()]\n",
    "\n",
    "# join pairs with label and probability\n",
    "labels = [target_names[number] for number in predictions]\n",
    "classifications = list(zip(similar_pairs, labels))\n",
    "list(zip(classifications, probabilities))\n",
    "entailment_neutral = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities)) if label == 'entailment' or label == 'neutral']\n",
    "#contradictions = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities)) if label != 'entailment' and label != 'neutral']\n",
    "#classifications = [[[probability, label], premise, hypothesis] for (((premise, hypothesis), label), probability) in list(zip(classifications, probabilities))]\n",
    "#for number, pair in enumerate(contradictions):\n",
    "#    print(number, pair)\n",
    "print(len(entailment_neutral))\n",
    "#print(len(contradictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Store results in persistent variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sentences = [[premise, hypothesis, label] for [[probability, label], premise, hypothesis] in entailment_neutral]\n",
    "#custom_sentences = [[premise, hypothesis, label] for [[probability, label], premise, hypothesis] in contradictions]\n",
    "%store custom_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluation graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "categories = ['A', 'B', 'C', 'D', 'E']\n",
    "values = [11, 1, 6, 5, 3]\n",
    "\n",
    "# Creating the bar diagram\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(categories, values, color='blue')\n",
    "plt.title('Bar Diagram')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Search for source document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "check = Chroma(persist_directory=\"/home/user123/contradictory-information/src/vectorization/vector_store/kb_langchain\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Free cash flow is defined as cash flow from ongoing business plus cash flow from investment activity'\n",
    "\n",
    "check.similarity_search(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
